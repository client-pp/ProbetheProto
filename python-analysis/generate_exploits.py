#python3
import os, codecs, logging, re, json, ast, random
from tqdm import tqdm
from pprint import pprint

from storage_match_utils import try_parse_json, log
from save_to_data import save_to_data
from match_configs import CONFIG
from joint_match_processing import find_joint_matches

TaintType = CONFIG.TaintType
priority_taintType = CONFIG.priority_taintType
refactor_dict = CONFIG.refactor_dict

# For URL-search checking
key2_str = '"KEY2"'
value_str = '"VALUE0"'
target_str = key2_str + value_str

possible_pp_website_record_name = "websites_to_pp_cookie_storage_0to200k.txt"

def new_parse_ppfound(line:str, idx:int, obj_list:list, file:str, websites_set, proto_addr):
    try:
        # line format: 
        # CONFIG.ppfound_str ObjectAddress <obj_addr>: [<JS_OBJECT_TYPE>] KeyTaintType <key_type> ValueTaintType <value_type> MessageId <id> KeyIs <key_content> ValueIs <value_content>
        # items = line.split(' ')
        # # TODO: len(items) could be greater than 8 because <str_contents> may contain ' '
        # assert len(items) == 14 and (items[0], items[1], items[4], items[6], items[8], items[10], items[12]) == (CONFIG.ppfound_str, \
        #     'ObjectAddress', 'KeyTaintType', 'ValueTaintType', 'MessageId', 'KeyIs', 'ValueIs')
        # obj_address, key_type, value_type, key_content, value_content = items[2], items[5], items[7], items[11], items[13]
        assert line.startswith(CONFIG.ppfound_str)
        ppfound_pattern = re.compile("ObjectAddress (.*): \[.*\] KeyTaintType (.*) ValueTaintType (.*) MessageId (\d*) KeyIs (.*) ValueIs (.*)")
        results = ppfound_pattern.search(line)
        if not results:
            return None
        obj_address, key_type, value_type, messageId, key_content, value_content = results[1], results[2], results[3], results[4], results[5], results[6]
        assert key_type in TaintType and value_type in TaintType
        obj_address = obj_address.rstrip(':')

        is_proto_fp = True
        is_data_flow_san = False

        # locate obj in obj_list
        for each_obj in reversed(obj_list):
            if obj_address == each_obj[0]:
                key1_type, key1_str, which_proto = each_obj[1], each_obj[2], each_obj[3]
                if obj_address == proto_addr:
                    is_proto_fp = False
                    # print(which_proto, key1_str, key_content, value_content)
                    is_data_flow_san = if_data_flow_san(key1_str)
                break
        else:
            log('{} no proper obj for ppFOUND {}'.format(file, line))
            return None

        key2_and_value_str = [key_content, value_content]
        for idx, each in enumerate(key2_and_value_str):
            if each.startswith('"') and each.endswith('"'):
                key2_and_value_str[idx] = each[1:-1]
            elif each.startswith('c"') and each.endswith('"'):
                key2_and_value_str[idx] = each[2:-1]
            elif each.startswith('#'):
                key2_and_value_str[idx] = each[1:]

        return key1_type, key_type, value_type, messageId, key1_str, key2_and_value_str[0], key2_and_value_str[1], is_proto_fp, is_data_flow_san
    except AssertionError as e:
        log('{} has error{} at {}'.format(file, line, e))
        return None

def if_data_flow_san(key1):
    possible_list = ["X19wcm90b19f", "\ud83d\udf56", "__PROTO__"]
    blacklist = ["__proto__", "prototype", "constructor", "["]
    if any([each in key1 for each in blacklist]):
        return False
    if any([each == key1 for each in possible_list]):
        return True
    if any([each.upper() == key1.upper() for each in blacklist]):
        return True
    return False

def parse_ppfound(line:str, idx:int, file:str, websites_set):
    # line format: 
    # CONFIG.ppfound_str KeyTaintType <key_type> ValueTaintType <value_type> MessageId <id> <str_contents>
    assert line.startswith(CONFIG.ppfound_str)
    items = line.split(' ')
    # len(items) could be greater than 8 because <str_contents> may contain ' '
    if len(items) < 8:
        return None
    flag = (CONFIG.ppfound_str in line) +\
      (CONFIG.ppfound_str == items[0]) +\
      ('KeyTaintType' == items[1]) +\
      ('ValueTaintType' == items[3])
    if flag != 4:
        return None
    key_type = items[2]
    value_type = items[4]
    # str_contents = items[-1] 
    str_contents = ''.join(items[7:]) # TODO: string processing
    key_content, value_content = split_str_contents(str_contents)

    # Unused websites_set now!
    # new_flag = (key_type == "Cookie" or key_type == "Storage") + (value_type == "Cookie" or value_type == "Storage")
    # if new_flag >= 1:
    # #     log(file.replace('_log_file','').replace('_', '.') + ': ' + line)

    # # if str_contents[:len(target_str)].upper() == target_str:
    #     site = file.replace('_log_file','').replace('_', '.')
    #     websites_set.add(site)
        # possible_pp_logger.info(f'{file}:{idx} {line}')
        # with open(os.path.join(root_path, possible_pp_website_record_name), 'a') as f0:
        #     site = file.replace('_log_file','').replace('_', '.')
        #     f0.write(f'{site}\n')

    # if key_type != value_type:
    #     warning_logger.info(f'{file}:{idx} warning {line}')

    return [key_type, value_type, key_content, value_content]

def parse_objTainted(line:str, idx:int, file:str, obj_proto_props:list, websites_set, location=None):
    # Line format: 
    # CONFIG.objTainted_str ObjectAddress: <obj_address>: [<JS_OBJECT_TYPE>] KeyTaintType <key_type> KeyIs <key1_content>
    # archaic: CONFIG.objTainted_str KeyTaintType <key_type><str_contents>
    # archaic: Should take extra efforts to split <key_type> and <str_contents>
    try:
        assert line.startswith(CONFIG.objTainted_str)
        objTainted_pattern = re.compile("ObjectAddress: (.*): \[.*\] KeyTaintType (.*) KeyIs (.*)")
        results = objTainted_pattern.search(line)
        if not results:
            return (None,)*5
        obj_address, key_type, key1_content = results[1], results[2], results[3]
        if not key_type in TaintType:
            for each_type in TaintType:
                if each_type in key_type:
                    key_type = each_type
                    break
        obj_address = obj_address.rstrip(':')
        if key1_content.startswith('"') and key1_content.endswith('"'):
            key1_content = key1_content[1:-1]
        elif key1_content.startswith('c"') and key1_content.endswith('"'):
            key1_content = key1_content[2:-1]
        elif key1_content.startswith('#'):
            key1_content = key1_content[1:]

        proto_is_polluted = False
        if CONFIG.statistic_mode == '__proto__':
            for pos, elem in enumerate(obj_proto_props):
                # check for other prototypes, e.g., 'HTMLDivElement', 'HTMLIFrameElement'
                if CONFIG.check_other_prototype and key1_content in ['__proto__', 'prototype'] and \
                    any([each in elem for each in CONFIG.OTHER_PROTOTYPE]):
                    for each in CONFIG.OTHER_PROTOTYPE:
                        if each in elem:
                            which_proto = each
                            # print(each, ' ', key1_content, ' ', location)
                    return obj_address, key_type, key1_content, True, which_proto

            # move start_pos in order to check Object.prototype properties
            for pos, elem in enumerate(obj_proto_props):
                if any(elem.startswith(each) for each in CONFIG.OBJ_PROTO_PROP):
                    start_pos = pos 
                    break
            else:
                return obj_address, key_type, key1_content, False, ''

            if set(each.split(':')[0] for each in obj_proto_props[start_pos:start_pos+len(CONFIG.OBJ_PROTO_PROP)]) == set(CONFIG.OBJ_PROTO_PROP):
                proto_is_polluted = True # really polluting Object.prototype
            
        #     for kk, each_prop in enumerate(CONFIG.OBJ_PROTO_PROP):
        #         if not obj_proto_props[start_pos + kk].startswith(each_prop):
        #             proto_is_polluted = False
        #             break
        #     else:
        #         proto_is_polluted = True
        # else:
        #     proto_is_polluted = False
        return obj_address, key_type, key1_content, proto_is_polluted, 'Object'
    except AssertionError as e:
        log('{} has error{} at {}'.format(file, line, e))
        return (None,)*4

    # archaic: 
    # assert items[1] == 'KeyTaintType'
    # contents = ''.join(items[2:]).replace(CONFIG.objTainted_str, '').replace('KeyTaintType', '')
    # for each_type in TaintType:
    #     if contents.startswith(each_type):
    #         key1_type = each_type
    #         break
    # else:
    #     # For strange cases
    #     for each_type in TaintType:
    #         if each_type in contents:
    #             key1_type = each_type
    #             break
    #     else:
    #         log("The key1_type of " + contents + " unidentified! ")
    #         return None
    
    # # content processing
    # key1_content = contents[contents.find(key1_type)+len(key1_type):]
    # if key1_content.startswith('"') and key1_content.endswith('"'):
    #     key1_content = key1_content[1:-1]
    # elif key1_content.startswith('c"') and key1_content.endswith('"'):
    #     key1_content = key1_content[2:-1]
    # elif key1_content.startswith('#'):
    #     key1_content = key1_content[1:]
    # else:
    #     log('New type of key1_content! ' + key1_content)
    # return key1_type, key1_content

def split_str_contents(str_contents:str):
    if str_contents.startswith('#'):
        begin_0_pos = 1
        split_pos = str_contents.find('c"')
        begin_1_pos = split_pos + len('c"')
        end_pos = -1
        if split_pos == -1: # not found
            split_pos = str_contents.find('"')
            begin_1_pos = split_pos + len('"')
            end_pos = -1
            if split_pos == -1: # not found
                split_pos = str_contents[1:].find('#')
                begin_1_pos = split_pos + len('#')
                end_pos = len(str_contents)
        cont0 = str_contents[begin_0_pos : split_pos]
        cont1 = str_contents[begin_1_pos : end_pos]
    else:
        if str_contents.startswith('c"'):
            begin_0_pos = 2
        elif str_contents.startswith('"'):
            begin_0_pos = 1
        else:
            log('Unidentified format in split_str_contents! ' + str_contents)
            return str_contents.split('""')[0], str_contents.split('""')[-1]
        
        no_escape_double_quote_content = str_contents.replace('\\"', '')
        split_pos = no_escape_double_quote_content.find('"c"')
        begin_1_pos = split_pos + len('"c"')
        end_pos = -1
        if split_pos == -1: # not found
            split_pos = no_escape_double_quote_content.find('""')
            begin_1_pos = split_pos + len('""')
            end_pos = -1
            if split_pos == -1: # not found
                split_pos = no_escape_double_quote_content[1:].find('"#')
                begin_1_pos = split_pos + len('"#')
                end_pos = len(no_escape_double_quote_content)
        cont0 = no_escape_double_quote_content[begin_0_pos : split_pos]
        cont1 = no_escape_double_quote_content[begin_1_pos : end_pos]
    return cont0, cont1

def dict_element_refactor(source_type_dict):
    new_dict = {}
    count_all_entries = 0
    count_all_domains = 0
    for value_type, value_each in source_type_dict.items():
        value_type = refactor_dict[value_type]
        for key1_type, key1_each in value_each.items():
            key1_type = refactor_dict[key1_type]
            for key2_type, counts in key1_each.items():
                key2_type = refactor_dict[key2_type]
                sorted_types = sorted([key1_type, key2_type, value_type], key=lambda taint:priority_taintType.index(taint))
                new_key = str(set(sorted_types))
                if not new_key in new_dict.keys():
                    new_dict[new_key] = [0 for i in range(len(counts))]
                for idx, elem in enumerate(counts):
                    if isinstance(elem, set): # elem is a set of websites
                        new_dict[new_key][idx] += len(elem)
                    elif isinstance(elem, int):
                        new_dict[new_key][idx] += elem
                count_all_entries += counts[2]
                count_all_domains += len(counts[3])
    print('count_all_entries: {} count_all_domains: {}'.format(count_all_entries, count_all_domains))
    return new_dict

def add_to_website_set(this_types:set, site:str, websites_set):
    if not this_types:
        return
    # types = [key1_type, key2_type, value_type]
    websites_set['All'].add(site)
    for each in ['Message', 'Cookie', 'Storage']:
        if each in this_types:
            websites_set[each].add(site)

if __name__ == "__main__":

    root_path = CONFIG.check_pp_log_dir
    write_root_path = CONFIG.stem
    write_to_files = CONFIG.write_to_txt_files
    generating_exploits = CONFIG.generating_exploits
    regenerate_website_set = True

    # possible_pp_website_all_record_name = "websites_all_to_pp_pattern1_new_0to600kplus.txt"
    # possible_pp_website_cookie_storage_record_name = "websites_to_pp_cookie_storage_0to600kplus.txt"
    # possible_pp_website_message_record_name = "websites_to_pp_message_0to600kplus.txt"
    possible_pp_website_all_record_name = "websites_all_to_pp_600kto1m.txt"
    possible_pp_website_cookie_storage_record_name = "websites_to_pp_cookie_storage_600kto1m.txt"
    possible_pp_website_message_record_name = "websites_to_pp_message_600kto1m.txt"
    count_domain = 0
    count_flow = 0
    count_flow_tp = 0
    total = 0
    strange_case_count = 0
    source_type_dict = {}
    if os.path.exists(CONFIG.website_set_txt) and os.path.getsize(CONFIG.website_set_txt) > 0 and (not regenerate_website_set):
        with open(os.path.join(CONFIG.stem, CONFIG.website_set_txt), 'r') as ff:
            contents = ff.read()
            website_set = ast.literal_eval(contents)
    else:
        website_set = {
            'All': set(),
            'Storage': set(), 
            'Cookie': set(),
            'Message': set()
        }
        with open(CONFIG.storage_data_file, 'r+') as f1, open(CONFIG.message_data_file, 'r+') as f2:
            if CONFIG.if_make_storage_data_js_empty:
                f1.truncate(0)
            if CONFIG.if_make_message_data_js_empty:
                f2.truncate(0)

            for file in tqdm(os.listdir(os.path.join(CONFIG.stem, root_path))+os.listdir(os.path.join(CONFIG.stem, CONFIG.check_pp_log_dir_2))): # Used when counting proto flows
            # for file in tqdm(os.listdir(os.path.join(CONFIG.stem, CONFIG.message_log_relative_path))): # +   # Used when generating exploits
            # for file in tqdm(os.listdir(os.path.join(CONFIG.stem, CONFIG.storage_log_relative_path))):
                if "log_file" in file: # and file in CONFIG.temp_target_sites:
                    # log("Checking " + file)
                    total += 1
                    # with codecs.open(os.path.join(CONFIG.stem, root_path, file), 'r', encoding='utf-8', errors='replace') as f0: # Used when counting proto flows
                    # if os.path.exists(os.path.join(CONFIG.stem, CONFIG.storage_log_relative_path, file)):
                    #     file_root_path = CONFIG.storage_log_relative_path
                    # elif os.path.exists(os.path.join(CONFIG.stem, CONFIG.message_log_relative_path, file)):
                    #     file_root_path = CONFIG.message_log_relative_path
                    # else:
                    #     raise ValueError
                    if os.path.exists(os.path.join(CONFIG.stem, CONFIG.check_pp_log_dir_2, file)):
                        file_root_path = CONFIG.check_pp_log_dir_2
                    elif os.path.exists(os.path.join(CONFIG.stem, CONFIG.check_pp_log_dir, file)):
                        file_root_path = CONFIG.check_pp_log_dir
                    else:
                        print(file+' not found! ')
                        continue
                    with codecs.open(os.path.join(CONFIG.stem, file_root_path, file), 'r', encoding='utf-8', errors='replace') as f0: # Used when generating exploits
                        contents = f0.read()
                        if not CONFIG.ppfound_str in contents:
                            continue

                        count_domain += 1
                        this_site = file.replace('_log_file','').replace('_', '.')
                        this_taint_types = set()
                        all_joint_matches = []

                        # Initialization
                        # state = None # use state to store the key1_type
                        # current_key1_content = []
                        # state_change_count = 0
                        # state_keep_count = 0
                        obj_taint_state_is_open = False # use this state to extract complete info about ObjTaintedDueToTaintKey
                        obj_taint_current_str = ''
                        obj_taint_info_list = []
                        ppfound_state_is_open = False
                        ppfound_state_current_str = ''

                        proto_addr = None
                        location = None

                        # if file in ['servicem8_com_log_file']:
                        #     continue

                        lines_list = contents.split('\n')
                        # print('URL is: ', this_site+"?__proto__[testk]=testv&__proto__.testk=testv&constructor[prototype][testk]=testv")
                        for idx, line in enumerate(lines_list):
                            if line.startswith(CONFIG.ppfound_str):
                                if CONFIG.objTainted_terminate_line_startswith in line:
                                    ppfound_state_is_open = False
                                    ppfound_state_current_str = ''
                                    log('{} ppFOUND within one line! {}'.format(this_site, line))
                                    continue
                                else:
                                    ppfound_state_is_open = True
                                    ppfound_state_current_str = line
                                    continue

                            elif ppfound_state_is_open and line.startswith(CONFIG.objTainted_terminate_line_startswith):
                                
                                ppfound_state_current_str += line
                                
                                # continue
                                # log(line)
                                # log(file.replace('_log_file','').replace('_', '.'))
                                # count_domain += 1
                                # website_set.add(line.split(' ')[-1])
                                
                                results = new_parse_ppfound(ppfound_state_current_str, idx, obj_taint_info_list, file, website_set, proto_addr)
                                ppfound_state_is_open = False
                                ppfound_state_current_str = ''
                                if not results:
                                    continue
                                key1_type, key2_type, value_type, messageId, key1_content, key2_content, value_content, is_fp, is_data_flow_san = results #[0], results[1]
                                this_taint_types = this_taint_types.union((key1_type, key2_type, value_type))

                                # 0616: check joint-flow fp
                                # if len(set((key1_type, key2_type, value_type))) == 1:
                                #     continue
                                # print(f'{file, idx, line, [rr for rr in results]}')

                                if generating_exploits:
                                    # Match the strings and generate exploits 
                                    joint_matches = find_joint_matches([['key1', key1_type, [key1_content]], \
                                        ['key2', key2_type, key2_content], \
                                            ['value', value_type, value_content]], file)
                                    # TODO: store the joint_matches to data.js
                                    # store to /home/zfk/Documents/process-cookies/taintchrome/cookie_storage_modify_extension/data.js
                                    # /home/zfk/Documents/process-cookies/taintchrome/postMessage_extension/data.js
                                    if joint_matches and joint_matches[0] and any([each[1] for each in joint_matches]):
                                        all_joint_matches += joint_matches
                                    # each element in joint_matches is a list: 
                                    # [<taint_type>, <replaced_content>, <site>, <url>, <additional_info>]
                                    # E.g.: 'Cookie', '__proto__=testk:testv', 'www.pge.com', 'www.pge.com', ''
                                        # 'Storage' = 'localStorage': <additional_info>=1, 'sessionStorage':<additional_info>=-1
                                        # 'Storage', {'testk':'testv'}, 
                                    # if not <taint_type> in ['Cookie', 'Storage', 'Message']: continue
                                    # For 'Message': <additional_info> = message_origin

                                # Count key1_type, key2_type, value_type
                                # source_type_dict[value_type][state][key2_type]: [flow_counts, domain_counts]
                                if not value_type in source_type_dict.keys(): 
                                    source_type_dict[value_type] = {}
                                if not key1_type in source_type_dict[value_type].keys():
                                    source_type_dict[value_type][key1_type] = {}
                                if not key2_type in source_type_dict[value_type][key1_type].keys():
                                    source_type_dict[value_type][key1_type][key2_type] = [0, set(), 0, set(), 0, set()]
                                source_type_dict[value_type][key1_type][key2_type][0] += 1 # each_count_flow
                                source_type_dict[value_type][key1_type][key2_type][1].add(this_site)
                                count_flow += 1

                                is_irrelevant = False
                                for each_type, each_str, original in zip([key1_type, key2_type], [key1_content, key2_content], [CONFIG.key1['check'], CONFIG.key2['check']]):
                                    if each_type in CONFIG.query_string_type_list and each_str not in original: 
                                        is_irrelevant = True
                                        break
                                if is_fp and not is_data_flow_san and key1_content in ['__proto__', 'prototype']:#, 'constructor', 'prototype']:
                                    source_type_dict[value_type][key1_type][key2_type][4] += 1 # obj_san flows
                                    source_type_dict[value_type][key1_type][key2_type][5].add(this_site)
                                if (CONFIG.statistic_mode == '__proto__' and not is_fp):
                                    
                                    if is_data_flow_san:
                                        pass
                                        # source_type_dict[value_type][key1_type][key2_type][4] += 1 # is_data_flow_san
                                        # source_type_dict[value_type][key1_type][key2_type][5].add(this_site)
                                    else:
                                        if not is_irrelevant:
                                            source_type_dict[value_type][key1_type][key2_type][2] += 1 # each_count_flow_tp
                                            source_type_dict[value_type][key1_type][key2_type][3].add(this_site)
                                            count_flow_tp += 1
                                            # if random.randint(0,9) == 0:
                                            #     print('MessageId: ', messageId, ' TaintType: ', refactor_dict[key2_type])
                                
                                # this_taint_types = this_taint_types.union((key1_type, key2_type, value_type))
                                

                                # if (state is None) or (state_change_count >= 4 and state_keep_count <= 5):
                                #     query_flag = False
                                #     for each_type in query_string_type_list:
                                #         if state == each_type and key2_type == each_type and value_type == each_type:
                                #             query_flag = True
                                #             break
                                #     if not query_flag: # Query string cases are not strange cases
                                #         log("{} {} strange key1_type: {} state_change_count {}; Detected at {}".format(file, idx, state, state_change_count, line))
                                #         strange_case_count += 1
                                # # state = None
                                # state_change_count = 0
                                # state_keep_count = 0

                            elif line.startswith(CONFIG.objTainted_str):
                                if CONFIG.objTainted_terminate_line_startswith in line:
                                    obj_taint_state_is_open = False
                                    obj_taint_current_str = ''
                                    continue
                                else:
                                    obj_taint_state_is_open = True
                                    obj_taint_current_str = line
                                    continue
                                # key1_type, key1_content = parse_objTainted(line, idx, file, website_set)
                                # if not key1_type:
                                #     continue
                                # if state != key1_type:
                                #     state_change_count += 1
                                #     state = key1_type
                                #     current_key1_content = [key1_content]
                                # else:
                                #     state_keep_count += 1
                                #     if key1_content not in current_key1_content:
                                #         current_key1_content.append(key1_content)
                            
                            elif obj_taint_state_is_open and line.startswith(CONFIG.objTainted_terminate_line_startswith):
                                
                                obj_taint_current_str += line
                                obj_proto_props = lines_list[max(0, idx - 18):idx]
                                obj_addr, key1_type, key1_content, is_proto_polluted, which_proto = parse_objTainted(obj_taint_current_str, idx, file, obj_proto_props, website_set, location)
                                obj_taint_state_is_open = False
                                obj_taint_current_str = ''
                                if not key1_type:
                                    continue
                                # TODO: correctly get object address, e.g., read address of ObjTaintedDueToTaintKey! when KeyIs '__proto__'
                                if [obj_addr, key1_type, key1_content, which_proto] not in obj_taint_info_list:
                                    obj_taint_info_list.append([obj_addr, key1_type, key1_content, which_proto])
                                    if CONFIG.statistic_mode == '__proto__' and is_proto_polluted: # strict mode
                                        proto_addr = obj_addr
                                # if state != key1_type:
                                #     state_change_count += 1
                                #     state = key1_type
                                #     current_key1_content = [key1_content]
                                # else:
                                #     state_keep_count += 1
                                #     if key1_content not in current_key1_content:
                                #         current_key1_content.append(key1_content)

                            # elif line.startswith(CONFIG.prototype_addr_str):
                            #     # store prototype address for checking
                            #     proto_addr = line.split(CONFIG.prototype_addr_str)[-1]

                            elif line.startswith("Sink_function:Location.setLocation from 0|"):
                                location = line[len("Sink_function:Location.setLocation from 0|\""):-1]
                                # print('URL is: ', location)
                            else:
                                continue

                        add_to_website_set(this_taint_types, this_site, website_set)
                        if all_joint_matches and generating_exploits:
                            save_to_data(all_joint_matches, f1, f2, CONFIG.storage_data_file, CONFIG.message_data_file)
                    
    try:
        if write_to_files:
            # with open(os.path.join(root_path, possible_pp_website_record_name), 'w') as ff:
            #     websites_to_pp = '\n'.join([str(idx)+','+each for idx,each in zip(range(len(website_set)),website_set)])
            #     ff.write(websites_to_pp)

            # Write to files
            cookie_storage_website_set = website_set['Cookie'].union(website_set['Storage'])
            with open(os.path.join(write_root_path, possible_pp_website_cookie_storage_record_name), 'w') as ff:
                websites_to_pp = '\n'.join([str(idx+1)+','+each for idx,each in zip(range(len(cookie_storage_website_set)),cookie_storage_website_set)])
                ff.write(websites_to_pp)
                ff.write('\n')
            print('Write to file: {} done! Total len: {}'.format(possible_pp_website_cookie_storage_record_name, len(cookie_storage_website_set)))

            message_website_set = website_set['Message']
            with open(os.path.join(write_root_path, possible_pp_website_message_record_name), 'w') as ff:
                websites_to_pp = '\n'.join([str(idx+1)+','+each for idx,each in zip(range(len(message_website_set)),message_website_set)])
                ff.write(websites_to_pp)
                ff.write('\n')
            print('Write to file: {} done! Total len: {}'.format(possible_pp_website_message_record_name, len(message_website_set)))

            all_website_set = website_set['All']
            with open(os.path.join(write_root_path, possible_pp_website_all_record_name), 'w') as ff:
                websites_to_pp = '\n'.join([str(idx+1)+','+each for idx,each in zip(range(len(all_website_set)),all_website_set)])
                ff.write(websites_to_pp)
                ff.write('\n')
            print('Write to file: {} done! Total len: {}'.format(possible_pp_website_all_record_name, len(all_website_set)))
    except:
        print('Errors occurred during writing to files')
    # pprint(source_type_dict)
    # pprint(website_set)
    
    # with open(os.path.join(CONFIG.stem, CONFIG.website_set_txt), 'w') as ff:
    #     pprint(website_set, ff)
    
    # Refactor source_type_dict
    # pprint(dict_element_refactor(source_type_dict))
    with open(os.path.join(CONFIG.stem, CONFIG.count_flow_log_file['proto']), 'w') as ff:
        # pprint(dict_element_refactor(source_type_dict), ff)
        pprint(source_type_dict, ff)
    # print(" total vul sites: ", count_domain, " total domains: ", total, "total vul fraction: ", float(count_domain)/float(total), " flow counts: ", count_flow, " strange_case_count: ", strange_case_count)
    # with open(os.path.join(CONFIG.stem, possible_pp_website_record_name), 'w') as ff:
    #     websites_to_pp = '\n'.join([str(idx+1)+','+each for idx,each in zip(range(len(website_set)),website_set)])
    #     ff.write(websites_to_pp)
    
    # for kk, vv in website_set.items():
    #     print(kk, ' ', len(vv))
